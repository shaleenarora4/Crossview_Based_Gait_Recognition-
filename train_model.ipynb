{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T06:40:06.226796Z",
     "start_time": "2019-02-04T06:39:52.389158Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import pickle\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Activation,Dense,Dropout,Flatten\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T07:05:04.643Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T06:40:40.052776Z",
     "start_time": "2019-02-04T06:40:06.237767Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Sweet Pickle\n",
      "Pickle is sweet\n",
      "17594\n",
      "17594\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "print(\"Generating Sweet Pickle\")\n",
    "with open('X.pkl','rb') as f:\n",
    "    X = pickle.load(f)\n",
    "    f.close()\n",
    "with open('Y.pkl','rb') as f:\n",
    "    Y = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "print(\"Pickle is sweet\")\n",
    "print(len(Y))\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T06:30:21.577695Z",
     "start_time": "2019-02-04T06:30:21.569701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 320, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T06:42:09.131258Z",
     "start_time": "2019-02-04T06:40:59.202575Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.20, random_state = 42)\n",
    "\n",
    "y_train,y_test = to_categorical(y_train),to_categorical(y_test)\n",
    "\n",
    "x_test,x_train = np.asarray(x_test), np.asarray(x_train)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-04T06:42:16.188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14075 samples, validate on 3519 samples\n",
      "Epoch 1/10\n",
      "14075/14075 [==============================] - 80s 6ms/step - loss: 2.4820 - acc: 0.3824 - val_loss: 1.2640 - val_acc: 0.6954\n",
      "Epoch 2/10\n",
      "14075/14075 [==============================] - 65s 5ms/step - loss: 0.8831 - acc: 0.7991 - val_loss: 0.7028 - val_acc: 0.8301\n",
      "Epoch 3/10\n",
      "14075/14075 [==============================] - 62s 4ms/step - loss: 0.4951 - acc: 0.8949 - val_loss: 0.4648 - val_acc: 0.8963\n",
      "Epoch 4/10\n",
      "14075/14075 [==============================] - 63s 4ms/step - loss: 0.3224 - acc: 0.9371 - val_loss: 0.3776 - val_acc: 0.9130\n",
      "Epoch 5/10\n",
      "11264/14075 [=======================>......] - ETA: 9s - loss: 0.2246 - acc: 0.9611"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(8,(5,5),padding='valid',input_shape=(240,320,3)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(Conv2D(8,(5,5),padding='valid',input_shape=(240,320,3)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(Conv2D(8,(5,5),padding='valid',input_shape=(240,320,3)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(Conv2D(8,(5,5),padding='valid',input_shape=(240,320,3)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(50,input_shape=(200,))) #Change according to the number of subjects. 50 is 50 subjects\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "model.save('test1.h5')\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T12:53:08.159051Z",
     "start_time": "2019-01-20T12:53:07.857181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.2324928e-12, 1.0050813e-10, 4.5384168e-09, 1.0000000e+00,\n",
       "        2.0590150e-10]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('D:\\\\MINOR_PROJECT\\\\casia b\\\\silhouettes\\\\003\\\\nm-02\\\\090\\\\003-nm-02-090-072.png')\n",
    "\n",
    "img = np.asarray(img)\n",
    "img = img.astype('float32')\n",
    "img = img/255\n",
    "img = img.reshape((1,240,320,3))\n",
    "\n",
    "predict_array = model.predict(img)\n",
    "print(\"Subject is : \" + predict_array.index(np.amax(predict_array)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16.0,
    "lenType": 16.0,
    "lenVar": 40.0
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1144px",
    "right": "20px",
    "top": "165px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
